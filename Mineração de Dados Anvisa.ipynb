{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "264f94c6",
   "metadata": {},
   "source": [
    "## Se necessário instalar as bibliotecas adicionais: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e92202",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146bf18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42388d3e",
   "metadata": {},
   "source": [
    "## Importação das bibliotecas e instanciar as variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a5e91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Requests do HTTP\n",
    "import requests\n",
    "\n",
    "#Criação e manipulação do dataframe\n",
    "import pandas as pd\n",
    "\n",
    "#Mineração de dados\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Criação de valores nulos\n",
    "import numpy as np\n",
    "\n",
    "#Pra ver o tempo de run do crawler \n",
    "from time import time\n",
    "\n",
    "#Lista de URL's de resoluções de janeiro até fevereiro de 2022\n",
    "lista_urls = ['https://www.in.gov.br/web/dou/-/resolucao-re-n-175-de-20-de-janeiro-de-2022-375565424',\n",
    "             'https://www.in.gov.br/web/dou/-/resolucao-re-n-255-de-27-de-janeiro-de-2022-376898876',\n",
    "             'https://www.in.gov.br/web/dou/-/resolucao-re-n-361-de-3-de-fevereiro-de-2022-378387845',\n",
    "             'https://www.in.gov.br/web/dou/-/resolucao-re-n-430-de-10-de-fevereiro-de-2022-379899450',\n",
    "             'https://www.in.gov.br/web/dou/-/resolucao-re-n-522-de-17-de-fevereiro-de-2022-381447439']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090368df",
   "metadata": {},
   "source": [
    "## Desenvolvimento das funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cefeeaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preencher_nulos(dataframe):\n",
    "    \n",
    "    '''Pega as 3 primeiras colunas do dataframe (resoluções, empresas e autorizações) e utiliza o método ffill\n",
    "    para preencher os valores nulos'''\n",
    "    \n",
    "    colunas = dataframe.columns[:3].tolist()\n",
    "    dataframe[colunas] = dataframe[colunas].ffill()\n",
    "    return dataframe\n",
    "\n",
    "def minerar_pagina(url):\n",
    "    \n",
    "    '''Função para entrar na url e minerar todas as tags <p> do site e adicionando elas em uma lista para\n",
    "    então depois fazer o processamento de texto dentro dessa lista e adicionar as respectivas informações\n",
    "    nas colunas certas no formato de dataframe do Pandas'''\n",
    "    \n",
    "    #Instanciando o tempo inicial \n",
    "    tempo_inicial = time()\n",
    "    \n",
    "    #Fazendo o request da página e passando para o BeautifulSoup    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    #Juntar todos os parágrafos em uma lista \n",
    "    info = [marca.text for marca in soup.find_all('p', class_='dou-paragraph')]\n",
    "\n",
    "    #É possível pegar as resoluções porque possuem classe única no HTML\n",
    "    lista_resolucoes = []\n",
    "    lista_resolucoes.append(soup.find('p', class_='identifica').text)\n",
    "    \n",
    "    #Todas as colunas que não possuem dados faltando e não precisam de tratamento adicional\n",
    "    lista_marcas = [produto.split(':')[1][1:] for produto in info if 'NOME DO PRODUTO E MARCA' in produto]\n",
    "    lista_processos = [processo.split(':')[1][1:] for processo in info if 'NUMERO DE PROCESSO' in processo]\n",
    "    lista_registros = [registro.split(':')[1][1:] for registro in info if 'NUMERO DE REGISTRO' in registro]\n",
    "    lista_vendas = [venda.split(':')[1][1:] for venda in info if 'VENDA E EMPREGO' in venda]\n",
    "    lista_apresentacoes = [apresentacao.split(':')[1][1:] for apresentacao in info if 'APRESENTAÇÃO' in apresentacao]\n",
    "    lista_validades = [validade.split(':')[1][1:] for validade in info if 'VALIDADE DO PRODUTO' in validade]\n",
    "    lista_categorias = [categoria.split(':')[1][1:] for categoria in info if 'CATEGORIA' in categoria]\n",
    "    lista_assuntos = [assunto.split(':')[1][1:] for assunto in info if 'ASSUNTO DA PETIÇÃO' in assunto]\n",
    "    \n",
    "    #Como é necessário que as colunas tenham o mesmo número de linhas, e só possui uma resolução por página, é\n",
    "    #necessário preencher o resto das linhas da lista de resoluções com valores nulos para depois repetir eles\n",
    "    for i in range(len(lista_marcas) - 1):\n",
    "        lista_resolucoes.append(np.nan)\n",
    "        \n",
    "    #Instanciar as listas vazias\n",
    "    empresas, autorizacoes, vencimentos, expedientes = ([] for i in range(4))\n",
    "\n",
    "    #Aqui são as colunas que não possuem o mesmo número de linhas e precisam de tratamento\n",
    "    #Para criar o mesmo número de linhas para todas, se um valor não está na linha que deveria estar,\n",
    "    #será criado um valor nulo no lugar dele\n",
    "    contador = 0  #Para verificar em qual linha estou e qual será a próxima\n",
    "    for linha in info:\n",
    "        #Sempre que tiver uma empresa, terá que ter uma autorização, então a lógica para ambos é a mesma\n",
    "        if 'NOME DA EMPRESA' in linha:\n",
    "            empresas.append(linha.split(':')[1][1:])\n",
    "        \n",
    "        if 'AUTORIZAÇÃO' in linha:\n",
    "            autorizacoes.append(linha.split(':')[1][1:])\n",
    "            \n",
    "        if 'VENCIMENTO' in linha:\n",
    "            vencimentos.append(linha.split(':')[1][1:])\n",
    "\n",
    "        if 'PRODUTO E MARCA' in linha:\n",
    "            if 'AUTORIZAÇÃO' not in ultima_linha:\n",
    "                empresas.append(np.nan)\n",
    "                autorizacoes.append(np.nan)\n",
    "\n",
    "        if 'APRESENTAÇÃO' in linha:\n",
    "            if 'VENCIMENTO' not in ultima_linha:\n",
    "                vencimentos.append(np.nan)\n",
    "                \n",
    "        #A coluna expedientes segue a lógica de verificar a próxima linha, pois não é possível verificar a última\n",
    "        if 'ASSUNTO DA PETIÇÃO' in linha:\n",
    "            if contador == (len(info) - 1):\n",
    "                expedientes.append(np.nan)\n",
    "                break\n",
    "                \n",
    "            if 'EXPEDIENTE' in info[contador + 1]:\n",
    "                expedientes.append(info[contador + 1].split(':')[1][1:])\n",
    "                \n",
    "            else:\n",
    "                expedientes.append(np.nan)\n",
    "                \n",
    "        contador += 1\n",
    "                \n",
    "        #Crio a variável de última linha, e como é a última coisa dentro do for, no próximo loop ela será a linha anterior\n",
    "        ultima_linha = linha \n",
    "    \n",
    "    #Dicionário que vai ser passado para a criação do dataframe local\n",
    "    dicionario = {'RESOLUCAO': [resolucao for resolucao in lista_resolucoes],\n",
    "                  'EMPRESA': empresas,\n",
    "                  'AUTORIZACAO': autorizacoes,\n",
    "                  'MARCA': [marca for marca in lista_marcas],\n",
    "                 'PROCESSO': [processo for processo in lista_processos],\n",
    "                 'REGISTRO': [registro for registro in lista_registros],\n",
    "                 'VENDA E EMPREGO': [venda for venda in lista_vendas],\n",
    "                  'VENCIMENTO': vencimentos,\n",
    "                 'APRESENTACAO': [apresentacao for apresentacao in lista_apresentacoes],\n",
    "                 'VALIDADE PRODUTO': [validade for validade in lista_validades],\n",
    "                 'CATEGORIA': [categoria for categoria in lista_categorias],\n",
    "                 'ASSUNTO PETICAO': [assunto for assunto in lista_assuntos],\n",
    "                 'EXPEDIENT E PETICAO': expedientes}\n",
    "    \n",
    "    #Adiciono o dataframe que foi criado da url a lista de todos os dataframes gerados\n",
    "    lista_dataframes.append(pd.DataFrame(data=dicionario))\n",
    "    \n",
    "    #Tempo que demorou para minerar uma página inteira\n",
    "    print(f'Essa página demorou {time() - tempo_inicial} segundos.')\n",
    "    \n",
    "#Juntar todos os dataframes gerados de cada página\n",
    "def juntar_dataframes(lista_de_dataframes):\n",
    "    dataframe = pd.concat(lista_de_dataframes)\n",
    "    return dataframe\n",
    "\n",
    "#Criar a coluna vazia de versão dentro do dataframe\n",
    "def criar_coluna_versao(dataframe):\n",
    "    dataframe['VERSAO'] = \"\"\n",
    "    \n",
    "def verificar_tamanho(dataframe):\n",
    "    return(f'O dataframe criado possui {dataframe.shape[0]} linhas e {dataframe.shape[1]} colunas.')\n",
    "    \n",
    "### Daqui para baixo são as funções de tratamento de dados, não são necessárias para o pedido oficial do cliente\n",
    "    \n",
    "#Padronizar todas as linhas das colunas de objetos em letras maiúsculas, importante para o tratamento de dados\n",
    "def transformar_maiusculo(dataframe):\n",
    "    colunas = dataframe.select_dtypes(include='object')\n",
    "    for coluna in colunas:\n",
    "        dataframe[coluna] = dataframe[coluna].str.upper()\n",
    "    \n",
    "#Separar a coluna categoria em ID e categoria, depois transformar a coluna ID para int    \n",
    "def separar_categoria(dataframe):\n",
    "    dataframe[['ID_CATEGORIA', 'CLASSE_CATEGORIA']] = dataframe.CATEGORIA.str.split(' ', 1, expand=True)\n",
    "    dataframe['ID_CATEGORIA'] = dataframe['ID_CATEGORIA'].astype(int)\n",
    "    dataframe.drop(columns=['CATEGORIA'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1c9f5b",
   "metadata": {},
   "source": [
    "## Minerando página por página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6ed8b3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essa página demorou 1.7073822021484375 segundos.\n",
      "Essa página demorou 0.5351197719573975 segundos.\n",
      "Essa página demorou 0.6211390495300293 segundos.\n",
      "Essa página demorou 0.5201160907745361 segundos.\n",
      "Essa página demorou 0.5411214828491211 segundos.\n",
      "BACKUP: O dataframe criado possui 991 linhas e 14 colunas.\n",
      "TRATAMENTO: O dataframe criado possui 991 linhas e 15 colunas.\n"
     ]
    }
   ],
   "source": [
    "#Lista vazia para dar o concat nos dataframes\n",
    "lista_dataframes = []\n",
    "\n",
    "#Iterando url por url e minerando a página\n",
    "for url in lista_urls:\n",
    "    minerar_pagina(url)\n",
    "\n",
    "#Criar o dataframe pedido pelo cliente e exportar ele para ter um backup antes de realizar o tratamento\n",
    "df = juntar_dataframes(lista_dataframes)\n",
    "\n",
    "#Funções que precisam estar na planilha de backup\n",
    "preencher_nulos(df)\n",
    "criar_coluna_versao(df)\n",
    "\n",
    "#Verificar a quantidade de informações mineradas\n",
    "print(f'BACKUP: {verificar_tamanho(df)}')\n",
    "\n",
    "#Salvando a planilha de backup\n",
    "df.to_excel('Planilha-Anvisa-Backup.xlsx', index=False)\n",
    "\n",
    "#Funções de tratamento de dados\n",
    "transformar_maiusculo(df)\n",
    "separar_categoria(df)\n",
    "\n",
    "#Verificar a quantidade de informações mineradas após tratamento\n",
    "print(f'TRATAMENTO: {verificar_tamanho(df)}')\n",
    "\n",
    "#Salvando a planilha tratada\n",
    "df.to_excel('Planilha-Anvisa-Tratada.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
